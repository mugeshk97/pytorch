{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE CLASSIFICATION USING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', download=True, train= True)\n",
    "test_data = MNIST(root='data/' , train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data/\n",
       "    Split: Test"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_data[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "Pytorch don't know to process with images so we need to transform images to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', \n",
    "                train=True,\n",
    "                transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "5\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image_tensor , label = dataset[0]\n",
    "print(image_tensor)  \n",
    "print(label)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = random_split(dataset, [50000, 10000])\n",
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # for calling the __init__ of the superclass (nn)\n",
    "        self.linear = nn.Linear(input_size, num_classes)    \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        out = functional.softmax(out,dim=1)\n",
    "        return out\n",
    "    \n",
    "model1  = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0207,  0.0257,  0.0295,  ...,  0.0056, -0.0224, -0.0316],\n",
       "         [ 0.0160, -0.0073, -0.0223,  ..., -0.0250,  0.0285, -0.0130],\n",
       "         [ 0.0156,  0.0223, -0.0124,  ..., -0.0270,  0.0002,  0.0073],\n",
       "         ...,\n",
       "         [-0.0230,  0.0175, -0.0029,  ..., -0.0219,  0.0067, -0.0259],\n",
       "         [ 0.0071, -0.0224,  0.0230,  ..., -0.0180, -0.0275,  0.0080],\n",
       "         [ 0.0048,  0.0349, -0.0204,  ..., -0.0206,  0.0226,  0.0026]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0115, -0.0168, -0.0060,  0.0282, -0.0289,  0.0123, -0.0310, -0.0171,\n",
       "          0.0061, -0.0174], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly initialized weights and biases\n",
    "print(model1.linear.weight.shape, model1.linear.bias.shape)\n",
    "list(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    output = model1(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0749, 0.1382,  ..., 0.0646, 0.0851, 0.1081],\n",
       "        [0.1211, 0.0781, 0.1221,  ..., 0.1137, 0.0842, 0.0918],\n",
       "        [0.1159, 0.0965, 0.1054,  ..., 0.1167, 0.1011, 0.1023],\n",
       "        ...,\n",
       "        [0.1180, 0.0731, 0.1550,  ..., 0.0803, 0.0697, 0.1047],\n",
       "        [0.1275, 0.0937, 0.1040,  ..., 0.0945, 0.1067, 0.0863],\n",
       "        [0.1144, 0.0969, 0.0898,  ..., 0.1068, 0.0990, 0.0985]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape # one batch 128 images for each image 10 op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0749, 0.1382, 0.1005, 0.1378, 0.1134, 0.0806, 0.0646, 0.0851,\n",
       "         0.1081],\n",
       "        [0.1211, 0.0781, 0.1221, 0.1204, 0.0875, 0.1177, 0.0634, 0.1137, 0.0842,\n",
       "         0.0918]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:2].data # sample ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Some of the values are negative but we need probability for this we are going to sigmoid or softmax function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 7, 0, 3, 1, 5, 7, 9, 7, 9, 7, 1, 2, 0, 9, 2, 7, 8, 1, 0, 0, 1, 9,\n",
      "        2, 9, 2, 0, 5, 7, 5, 9, 1, 9, 5, 3, 2, 7, 7, 9, 9, 0, 8, 1, 3, 2, 5, 7,\n",
      "        7, 7, 1, 7, 1, 2, 9, 8, 7, 2, 7, 0, 8, 2, 9, 7, 2, 0, 4, 9, 8, 7, 7, 5,\n",
      "        2, 9, 8, 8, 8, 7, 8, 5, 9, 2, 3, 9, 2, 9, 4, 2, 7, 7, 2, 9, 2, 7, 7, 7,\n",
      "        3, 9, 0, 7, 2, 0, 9, 9, 2, 7, 9, 5, 5, 7, 9, 1, 3, 7, 9, 7, 5, 7, 2, 8,\n",
      "        9, 9, 9, 2, 8, 2, 3, 3])\n",
      "tensor([0.1382, 0.1221, 0.1167, 0.1256, 0.1159, 0.1224, 0.1196, 0.1450, 0.1245,\n",
      "        0.1338, 0.1418, 0.1235, 0.1194, 0.1311, 0.1231, 0.1356, 0.1405, 0.1633,\n",
      "        0.1147, 0.1182, 0.1241, 0.1367, 0.1182, 0.1206, 0.1369, 0.1540, 0.1240,\n",
      "        0.1292, 0.1157, 0.1317, 0.1175, 0.1210, 0.1171, 0.1291, 0.1441, 0.1243,\n",
      "        0.1475, 0.1250, 0.1180, 0.1201, 0.1216, 0.1253, 0.1221, 0.1283, 0.1198,\n",
      "        0.1158, 0.1330, 0.1195, 0.1211, 0.1238, 0.1242, 0.1248, 0.1131, 0.1247,\n",
      "        0.1408, 0.1315, 0.1166, 0.1345, 0.1259, 0.1198, 0.1167, 0.1327, 0.1241,\n",
      "        0.1233, 0.1251, 0.1223, 0.1167, 0.1270, 0.1319, 0.1281, 0.1316, 0.1306,\n",
      "        0.1469, 0.1220, 0.1306, 0.1174, 0.1142, 0.1257, 0.1221, 0.1217, 0.1344,\n",
      "        0.1277, 0.1241, 0.1239, 0.1247, 0.1249, 0.1146, 0.1177, 0.1242, 0.1277,\n",
      "        0.1285, 0.1388, 0.1305, 0.1150, 0.1365, 0.1255, 0.1182, 0.1253, 0.1315,\n",
      "        0.1170, 0.1252, 0.1280, 0.1203, 0.1371, 0.1203, 0.1189, 0.1179, 0.1191,\n",
      "        0.1220, 0.1201, 0.1331, 0.1195, 0.1206, 0.1287, 0.1295, 0.1120, 0.1355,\n",
      "        0.1267, 0.1374, 0.1116, 0.1167, 0.1196, 0.1283, 0.1355, 0.1197, 0.1550,\n",
      "        0.1346, 0.1211], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs , preds = torch.max(output, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 0, 0, 2, 5, 8, 2, 2, 2, 8, 1, 1, 3, 1, 0, 2, 5, 3, 1, 8, 0, 2, 9,\n",
       "        3, 8, 7, 5, 5, 0, 8, 9, 1, 9, 6, 0, 5, 7, 7, 4, 7, 9, 5, 7, 7, 2, 4, 7,\n",
       "        9, 1, 7, 4, 2, 3, 7, 9, 3, 8, 7, 8, 8, 0, 5, 3, 0, 3, 2, 5, 3, 7, 3, 0,\n",
       "        6, 0, 8, 6, 4, 2, 2, 9, 8, 3, 3, 5, 5, 3, 7, 4, 7, 5, 0, 2, 5, 5, 6, 6,\n",
       "        4, 5, 7, 1, 6, 5, 0, 8, 0, 4, 2, 7, 8, 9, 3, 9, 0, 1, 5, 4, 4, 7, 3, 7,\n",
       "        8, 9, 7, 3, 1, 5, 4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 7, 0, 3, 1, 5, 7, 9, 7, 9, 7, 1, 2, 0, 9, 2, 7, 8, 1, 0, 0, 1, 9,\n",
       "        2, 9, 2, 0, 5, 7, 5, 9, 1, 9, 5, 3, 2, 7, 7, 9, 9, 0, 8, 1, 3, 2, 5, 7,\n",
       "        7, 7, 1, 7, 1, 2, 9, 8, 7, 2, 7, 0, 8, 2, 9, 7, 2, 0, 4, 9, 8, 7, 7, 5,\n",
       "        2, 9, 8, 8, 8, 7, 8, 5, 9, 2, 3, 9, 2, 9, 4, 2, 7, 7, 2, 9, 2, 7, 7, 7,\n",
       "        3, 9, 0, 7, 2, 0, 9, 9, 2, 7, 9, 5, 5, 7, 9, 1, 3, 7, 9, 7, 5, 7, 2, 8,\n",
       "        9, 9, 9, 2, 8, 2, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,labels):\n",
    "    _, pred = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(pred == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1797)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2993, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_func(output, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one forward propogation of the logistic regression\n",
    "\n",
    "### Let's Build the complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                  # Generate predictions\n",
    "        loss = functional.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self.forward(images)                    # Generate predictions\n",
    "        loss = functional.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)                   # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3256239891052246, 'val_acc': 0.08890426903963089}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.4309, val_acc: 0.8781\n",
      "Epoch [1], val_loss: 0.3536, val_acc: 0.8932\n",
      "Epoch [2], val_loss: 0.3272, val_acc: 0.8979\n",
      "Epoch [3], val_loss: 0.3125, val_acc: 0.9024\n",
      "Epoch [4], val_loss: 0.3028, val_acc: 0.9061\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these values with your results\n",
    "history = [result0] + history1\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
